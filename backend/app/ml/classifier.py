# =============================================================================
# FASHION-MNIST –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† (classifier.py)
# =============================================================================
# –ú–æ–¥—É–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–¥–µ–∂–¥—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏, 
# –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ Fashion-MNIST.
# 
# Fashion-MNIST —Å–æ–¥–µ—Ä–∂–∏—Ç 10 –∫–ª–∞—Å—Å–æ–≤ –æ–¥–µ–∂–¥—ã:
# 0: T-shirt/top (–§—É—Ç–±–æ–ª–∫–∞)
# 1: Trouser (–ë—Ä—é–∫–∏)
# 2: Pullover (–ü—É–ª–æ–≤–µ—Ä)
# 3: Dress (–ü–ª–∞—Ç—å–µ)
# 4: Coat (–ü–∞–ª—å—Ç–æ)
# 5: Sandal (–°–∞–Ω–¥–∞–ª–∏–∏)
# 6: Shirt (–†—É–±–∞—à–∫–∞)
# 7: Sneaker (–ö—Ä–æ—Å—Å–æ–≤–∫–∏)
# 8: Bag (–°—É–º–∫–∞)
# 9: Ankle boot (–ë–æ—Ç–∏–Ω–∫–∏)
# =============================================================================

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
import torchvision.transforms as transforms

# =============================================================================
# –ú–ê–ü–ü–ò–ù–ì –ö–õ–ê–°–°–û–í
# =============================================================================
# Fashion-MNIST class ID -> –Ω–∞—à clothing-categories.json ID
FASHION_MNIST_CLASSES = {
    0: {"id": "t-shirt", "name": "–§—É—Ç–±–æ–ª–∫–∞", "type": "top"},
    1: {"id": "trouser", "name": "–ë—Ä—é–∫–∏", "type": "bottom"},
    2: {"id": "pullover", "name": "–ü—É–ª–æ–≤–µ—Ä", "type": "top"},
    3: {"id": "dress", "name": "–ü–ª–∞—Ç—å–µ", "type": "full"},
    4: {"id": "coat", "name": "–ü–∞–ª—å—Ç–æ", "type": "top"},
    5: {"id": "sandal", "name": "–°–∞–Ω–¥–∞–ª–∏–∏", "type": "shoes"},
    6: {"id": "shirt", "name": "–†—É–±–∞—à–∫–∞", "type": "top"},
    7: {"id": "sneaker", "name": "–ö—Ä–æ—Å—Å–æ–≤–∫–∏", "type": "shoes"},
    8: {"id": "bag", "name": "–°—É–º–∫–∞", "type": "accessory"},
    9: {"id": "ankle-boot", "name": "–ë–æ—Ç–∏–Ω–∫–∏", "type": "shoes"},
}


# =============================================================================
# –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ù–ï–ô–†–û–ù–ù–û–ô –°–ï–¢–ò (CNN)
# =============================================================================
class FashionCNN(nn.Module):
    """
    –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–¥–µ–∂–¥—ã.
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - 2 —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ—è —Å max pooling
    - 2 –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–ª–æ—è
    - Dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    
    –í—Ö–æ–¥: 28x28 grayscale –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    –í—ã—Ö–æ–¥: 10 –∫–ª–∞—Å—Å–æ–≤
    """
    def __init__(self):
        super(FashionCNN, self).__init__()
        
        # –ü–µ—Ä–≤—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫: 1 -> 32 –∫–∞–Ω–∞–ª–æ–≤
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        
        # –í—Ç–æ—Ä–æ–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫: 32 -> 64 –∫–∞–Ω–∞–ª–æ–≤
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        
        # –¢—Ä–µ—Ç–∏–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫: 64 -> 128 –∫–∞–Ω–∞–ª–æ–≤
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        
        # Max pooling
        self.pool = nn.MaxPool2d(2, 2)
        
        # Dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
        self.dropout = nn.Dropout(0.25)
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        # –ü–æ—Å–ª–µ 3 pooling —Å–ª–æ—ë–≤: 28/2/2/2 = 3.5, –Ω–æ —É –Ω–∞—Å —Ç–æ–ª—å–∫–æ 2 pooling = 7x7
        self.fc1 = nn.Linear(128 * 7 * 7, 256)
        self.fc2 = nn.Linear(256, 10)
    
    def forward(self, x):
        # Conv1 -> BN -> ReLU -> Pool
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        
        # Conv2 -> BN -> ReLU -> Pool
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        
        # Conv3 -> BN -> ReLU (–±–µ–∑ pool)
        x = F.relu(self.bn3(self.conv3(x)))
        
        # Flatten
        x = x.view(-1, 128 * 7 * 7)
        
        # FC1 -> ReLU -> Dropout
        x = self.dropout(F.relu(self.fc1(x)))
        
        # FC2 (–≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π)
        x = self.fc2(x)
        
        return x


# =============================================================================
# –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –û–î–ï–ñ–î–´
# =============================================================================
class ClothingClassifier:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–¥–µ–∂–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ Fashion-MNIST.
    
    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        classifier = ClothingClassifier()
        category = classifier.predict("path/to/image.jpg")
    """
    
    def __init__(self, model_path: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.
        
        Args:
            model_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ (.pth)
        """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = FashionCNN().to(self.device)
        
        # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if model_path is None:
            model_path = os.path.join(
                os.path.dirname(__file__), 
                "weights", 
                "fashion_mnist_cnn.pth"
            )
        
        self.model_path = model_path
        self.model_loaded = False
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å–∞
        if os.path.exists(model_path):
            self._load_model()
        else:
            print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ train_fashion_mnist.py –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        self.transform = transforms.Compose([
            transforms.Resize((28, 28)),
            transforms.Grayscale(num_output_channels=1),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏."""
        try:
            self.model.load_state_dict(
                torch.load(self.model_path, map_location=self.device)
            )
            self.model.eval()
            self.model_loaded = True
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.model_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.model_loaded = False
    
    def predict(self, image_path: str) -> dict:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–¥–µ–∂–¥—ã.
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            
        Returns:
            dict: {"id": "t-shirt", "name": "–§—É—Ç–±–æ–ª–∫–∞", "type": "top", "confidence": 0.95}
        """
        if not self.model_loaded:
            print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º unknown")
            return {"id": "unknown", "name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ", "type": "other", "confidence": 0.0}
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(image_path).convert("RGB")
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = F.softmax(outputs, dim=1)
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                top_probs, top_classes = torch.topk(probabilities, 3)
                
                print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è {os.path.basename(image_path)}:")
                for i in range(3):
                    class_id = top_classes[0][i].item()
                    conf = top_probs[0][i].item()
                    class_info = FASHION_MNIST_CLASSES.get(class_id, {"name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"})
                    print(f"   #{i+1}: {class_info['name']} ({conf:.1%})")
                
                confidence, predicted = torch.max(probabilities, 1)
                
                class_id = predicted.item()
                conf = confidence.item()
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∞—Å—Å–µ
            class_info = FASHION_MNIST_CLASSES.get(class_id, {
                "id": "unknown", "name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ", "type": "other"
            })
            
            result = {
                "id": class_info["id"],
                "name": class_info["name"],
                "type": class_info["type"],
                "confidence": round(conf, 4)
            }
            
            print(f"   ‚úÖ –ò—Ç–æ–≥: {result['name']} ({result['confidence']:.1%})\n")
            
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            return {"id": "unknown", "name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ", "type": "other", "confidence": 0.0}
    
    def predict_top_k(self, image_path: str, k: int = 3) -> list:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-K –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∏–∑ k –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        """
        if not self.model_loaded:
            return []
        
        try:
            image = Image.open(image_path).convert("RGB")
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = F.softmax(outputs, dim=1)
                top_probs, top_classes = torch.topk(probabilities, k)
            
            results = []
            for i in range(k):
                class_id = top_classes[0][i].item()
                conf = top_probs[0][i].item()
                class_info = FASHION_MNIST_CLASSES.get(class_id, {
                    "id": "unknown", "name": "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ", "type": "other"
                })
                results.append({
                    "id": class_info["id"],
                    "name": class_info["name"],
                    "type": class_info["type"],
                    "confidence": round(conf, 4)
                })
            
            return results
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            return []


# =============================================================================
# SINGLETON INSTANCE
# =============================================================================
_classifier_instance = None

def get_classifier() -> ClothingClassifier:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç singleton —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.
    –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ.
    """
    global _classifier_instance
    if _classifier_instance is None:
        _classifier_instance = ClothingClassifier()
    return _classifier_instance
