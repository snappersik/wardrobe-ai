# =============================================================================
# DOCKER COMPOSE - ОРКЕСТРАЦИЯ КОНТЕЙНЕРОВ
# =============================================================================
# Этот файл описывает все сервисы (контейнеры) нашего приложения.
# Docker Compose позволяет запускать несколько контейнеров одной командой:
# docker-compose up --build
# =============================================================================

version: '3.8'

services:
  # ===========================================================================
  # СЕРВИС 1: БАЗА ДАННЫХ POSTGRESQL
  # ===========================================================================
  # PostgreSQL - реляционная база данных для хранения пользователей,
  # одежды, образов и логов аудита.
  db:
    # Образ PostgreSQL версии 15 на Alpine Linux (минимальный размер)
    image: postgres:15-alpine
    
    # Имя контейнера для удобства (docker ps покажет это имя)
    container_name: wardrobe_db
    
    # Автоматический перезапуск при падении
    restart: always
    
    # Переменные окружения для инициализации PostgreSQL
    environment:
      # Имя пользователя базы данных
      POSTGRES_USER: postgres
      # Пароль для подключения к базе данных
      POSTGRES_PASSWORD: 12345
      # Имя базы данных (создаётся автоматически)
      POSTGRES_DB: wardrobe_ai
    
    # Проброс портов: хост:контейнер
    # Порт 4242 на хосте -> 5432 внутри контейнера (стандартный порт PostgreSQL)
    ports:
      - "4242:5432"
    
    # Тома для сохранения данных при перезапуске контейнера
    # Без этого все данные удалятся при остановке контейнера
    volumes:
      - postgres_data:/var/lib/postgresql/data
    
    # Проверка здоровья - бекенд ждёт пока БД будет готова
    # pg_isready проверяет что PostgreSQL принимает подключения
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s   # Проверять каждые 5 секунд
      timeout: 5s    # Таймаут проверки
      retries: 5     # Количество попыток

  # ===========================================================================
  # СЕРВИС 3: MONGODB (NO SQL DATABASE)
  # ===========================================================================
  # MongoDB - документоориентированная база данных для хранения логов аудита.
  # Требование проекта: использовать MongoDB для неструктурированных данных.
  mongo:
    image: mongo:latest
    container_name: wardrobe_mongo
    restart: always
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 5s
      timeout: 5s
      retries: 5

  # ===========================================================================
  # СЕРВИС 4: ML WORKER (TRAINING)
  # ===========================================================================
  # Отдельный сервис для долгого обучения моделей.
  # Работает в фоне, чтобы не блокировать основной API.
  ml_worker:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    container_name: wardrobe_ml_worker
    restart: always
    # Запускаем скрипт воркера вместо веб-сервера
    command: python -m app.ml.worker
    environment:
      DATABASE_URL: postgresql+asyncpg://postgres:12345@db:5432/wardrobe_ai
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: 12345
      POSTGRES_DB: wardrobe_ai
      # Общие пути
      ML_SHARED_PATH: /app/ml_shared
    volumes:
      # Доступ к загруженным фото (для обучения)
      - ./backend/uploads:/app/uploads
      # Общий том для моделей и датасетов
      - ml_shared_data:/app/ml_shared
    depends_on:
      db:
        condition: service_healthy

  # ===========================================================================
  # СЕРВИС 2: BACKEND (FASTAPI + PYTHON)
  # ===========================================================================
  # Бекенд API на FastAPI - обрабатывает все HTTP-запросы от фронтенда:
  # - Регистрация и авторизация пользователей
  # - Загрузка и управление одеждой
  # - Создание и редактирование образов
  # - API для AI-генерации
  backend:
    # Собираем образ из Dockerfile в папке ./backend
    build: ./backend
    
    # Имя контейнера
    container_name: wardrobe_backend
    
    # Автоматический перезапуск
    restart: always
    
    # Проброс портов: 8000 на хосте -> 8000 в контейнере
    ports:
      - "8000:8000"
    
    # Переменные окружения для бекенда
    # Эти значения переопределяют .env файл внутри контейнера
    environment:
      # URL подключения к базе данных (db - это имя сервиса выше)
      # В Docker Compose контейнеры находят друг друга по именам сервисов
      DATABASE_URL: postgresql+asyncpg://postgres:12345@db:5432/wardrobe_ai
      
      # URL подключения к MongoDB
      MONGO_URL: mongodb://mongo:27017
      
      # Секретный ключ для JWT токенов (хеширование и подпись)
      SECRET_KEY: KdvW21abf!nNJ1s_P6B0diWN2j
      
      # Алгоритм шифрования JWT токенов
      ALGORITHM: HS256
      
      # Время жизни токена авторизации в минутах
      ACCESS_TOKEN_EXPIRE_MINUTES: 60
      
      # Режим отладки (True = подробные ошибки)
      DEBUG: "True"
      
      # Путь для загрузки фотографий одежды
      UPLOADS_PATH: ./uploads

      # Путь к общим ML данным
      ML_SHARED_PATH: /app/ml_shared
    
    # Монтируем папку uploads для сохранения загруженных файлов
    volumes:
      - ./backend/uploads:/app/uploads
      # Общий том для моделей
      - ml_shared_data:/app/ml_shared
    
    # Зависимость: бекенд запустится только когда БД будет healthy
    depends_on:
      db:
        condition: service_healthy
      mongo:
        condition: service_healthy

# =============================================================================
# ТОМА (VOLUMES) - ПОСТОЯННОЕ ХРАНИЛИЩЕ
# =============================================================================
# Тома сохраняют данные между перезапусками контейнеров.
# Без томов все данные в контейнере удаляются при остановке.
volumes:
  # Том для данных PostgreSQL
  postgres_data:
  # Том для данных MongoDB
  mongo_data:
  # Том для общих ML данных (модели, датасеты)
  ml_shared_data: